# -*- coding: utf-8 -*-
"""Video Games Reccomendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11tboydNTvSZWauS7qlUbow5hAOuwSUQ1

# **Renaldi Panji Wibowo**

## **[Discovering Hidden Trends in Global Video Games](https://www.kaggle.com/datasets/thedevastator/discovering-hidden-trends-in-global-video-games/code)**
"""

#Importing the Libraries
import numpy as np
import pandas as pd
import datetime
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn import metrics

import warnings
import sys
if not sys.warnoptions:
    warnings.simplefilter("ignore")
np.random.seed(42)
from functools import reduce
pd.set_option('display.max_columns', None)

df = pd.read_csv('Video Games Sales.csv')

df

df.info()

"""## **Membersihkan Data**

### **Memilih Fitur**
"""

df.rename(columns = {'index':'User_ID', 'Game Title':'Game_Title'}, inplace = True)
selected_df = df[['User_ID', 'Game_Title',	'Platform',	'Year',	'Genre',	'Publisher', 'Review']]

clean_df = selected_df.dropna()

clean_df.info()

clean_df.head()

"""### **Format Ulang Fitur**"""

print('Jumlah User ID: ', len(clean_df.User_ID.unique()))
print('Jumlah Nama Game: ', len(clean_df.Game_Title.unique()))
print('Jumlah Genre: ', len(clean_df.Genre.unique()))

clean_df['Review'] = round(clean_df['Review'])
clean_df

clean_df.info()

"""### **Membuat Game ID Produk**"""

LE = LabelEncoder()

clean_df['Game_ID'] = LE.fit_transform(clean_df['Game_Title'])

clean_df

for col in clean_df:
    print(f"\033[1m{col} \n{20 * '-'}\033[0m")
    print(clean_df[col].value_counts(), '\n')

"""### **Menghapus Data Duplikat**"""

clean_df = clean_df.drop_duplicates('Game_ID')
clean_df = clean_df.reset_index(drop=True)
clean_df

"""### **Visualisasi Data**"""

# Menghitung jumlah game untuk setiap platform
platform_counts = df['Platform'].value_counts()

# Membuat plot bar untuk 10 platform terbesar
plt.figure(figsize=(10, 6))
platform_counts.plot(kind='bar')
plt.title('Visualisasi Data Platform dengan Jumlah Game Terbanyak')
plt.xlabel('Platform')
plt.ylabel('Jumlah Game')
plt.xticks(rotation=45)
plt.show()

# Menghitung jumlah game untuk setiap publisher
publisher_counts = df['Publisher'].value_counts().head(10)

# Membuat plot bar untuk 10 publisher terbesar
plt.figure(figsize=(10, 6))
publisher_counts.plot(kind='bar')
plt.title('Top 10 Publisher dengan Jumlah Game Terbanyak')
plt.xlabel('Publisher')
plt.ylabel('Jumlah Game')
plt.xticks(rotation=45)
plt.show()

# Ambil 10 genre dengan jumlah terbanyak
top_genres = df['Genre'].value_counts()

# Buat plot bar
plt.figure(figsize=(10, 6))
plt.bar(top_genres.index, top_genres.values)
plt.xlabel('Genre')
plt.ylabel('Jumlah Game')
plt.title('Visualisasi Data Genre Games')
plt.xticks(rotation=45)
plt.show()

# Hitung jumlah game yang dirilis pada setiap tahun
game_count_by_year = df['Year'].value_counts().sort_index()

# Plot visualisasi
plt.figure(figsize=(10, 6))

# Plot seluruh bar
plt.bar(game_count_by_year.index, game_count_by_year.values, color='blue')

# Temukan nilai tertinggi pada tahun 2008
max_count = game_count_by_year[2008]
max_index = game_count_by_year.index[game_count_by_year.index == 2008].values[0]

# Plot bar khusus untuk tahun 2008 dengan warna merah
plt.bar(max_index, max_count, color='green')

plt.xlabel('Tahun')
plt.ylabel('Jumlah Game')
plt.title('Jumlah Game yang Dirilis pada Tahun Tertentu')

plt.show()

"""## **Model Development dengan Content Based Filtering**"""

game_id = clean_df['Game_ID'].tolist()

genre = clean_df['Genre'].tolist()

title = clean_df['Game_Title'].tolist()

print('Total Game Id = ',len(game_id))
print('Total Genre = ',len(genre))
print('Total Game Tittle = ',len(title))

product_new = pd.DataFrame({
    'game_id': game_id,
    'genre': genre,
    'title': title
})
product_new

first_df = product_new
first_df.sample(5)

"""### **TF-IDF Vectorizer**"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()
tf.fit(first_df['genre'])
feature_names = tf.get_feature_names_out()

print("Daftar fitur (kata):", feature_names)

tfidf_matrix = tf.fit_transform(first_df['genre'])

tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=first_df['title']
).sample(10, axis=1).sample(10, axis=0)

"""## **Cosine Similarity**"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=first_df['title'], columns=first_df['title'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""## **Mendapatkan Rekomendasi**"""

def game_recommendations(nama_game, similarity_data=cosine_sim_df, items=first_df[['title', 'genre']], k=5):
    index = similarity_data.loc[:,nama_game].to_numpy().argpartition(
        range(-1, -k, -1))

    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    closest = closest.drop(nama_game, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

first_df[first_df.title.eq('Super Mario Bros.')]

game_recommendations('Super Mario Bros.')

"""## **Model Development dengan Collaborative Filtering**"""

user_id = clean_df['User_ID'].tolist()

game_id = clean_df['Game_ID'].tolist()

title = clean_df['Game_Title'].tolist()

platform = clean_df['Platform'].tolist()

year = clean_df['Year'].tolist()

genre = clean_df['Genre'].tolist()

publisher = clean_df['Publisher'].tolist()

rating = clean_df['Review'].tolist()

print(len(user_id))
print(len(game_id))
print(len(rating))

rating_new = pd.DataFrame({
    'user_id': user_id,
    'game_id' : game_id,
    'title' : title,
    'platform' : platform,
    'year' : year,
    'genre' : genre,
    'publisher' : publisher,
    'rating': rating
})
rating_new

second_df = rating_new
second_df.sample(5)

"""## **Mempersiapkan Data**"""

user_ids = second_df['user_id'].unique().tolist()
print('list user_id: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

game_ids = second_df['game_id'].unique().tolist()

game_to_game_encoded = {x: i for i, x in enumerate(game_ids)}

game_encoded_to_game = {i: x for i, x in enumerate(game_ids)}

second_df['user'] = second_df['user_id'].map(user_to_user_encoded)

second_df['game'] = second_df['game_id'].map(game_to_game_encoded)

num_users = len(user_to_user_encoded)
print(num_users)

num_game = len(game_to_game_encoded)
print(num_game)

min_rating = min(second_df['rating'])

max_rating = max(second_df['rating'])

print('Number of User: {}, Number of Game: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_game, min_rating, max_rating
))

"""## **Membagi Data untuk Training dan Validasi**"""

second_df = second_df.sample(frac=1, random_state=42)
second_df

x = second_df[['user','game']].values

y = second_df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * second_df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""## **Proses Training**"""

from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

class RecommenderNet(tf.keras.Model):

  def __init__(self, num_users, num_game, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_game = num_game
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.game_embedding = layers.Embedding(
        num_game,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.game_bias = layers.Embedding(num_game, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    game_vector = self.game_embedding(inputs[:, 1])
    game_bias = self.game_bias(inputs[:, 1])

    dot_user_game = tf.tensordot(user_vector, game_vector, 2)

    x = dot_user_game + user_bias + game_bias

    return tf.nn.sigmoid(x)

model = RecommenderNet(num_users, num_game, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""## **Visualisasi Metrik**"""

# Simpan nilai loss dari training dan validation ke dalam variabel tersendiri
train_rmse = history.history['root_mean_squared_error']
val_rmse = history.history['val_root_mean_squared_error']

# Buat plot dengan warna dan gaya garis yang berbeda untuk training dan validation
plt.plot(train_rmse, color='b', label='Training RMSE')
plt.plot(val_rmse, color='r', linestyle='dashed', label='Validation RMSE')

# Tambahkan judul, label sumbu, dan legenda
plt.title('Root Mean Squared Error History')
plt.xlabel('Epoch')
plt.ylabel('Root Mean Squared Error')
plt.legend(loc='upper right')

# Menambahkan grid untuk memudahkan pembacaan
plt.grid()

# Tampilkan plot
plt.show()

# Menyimpan nilai loss dari training dan validation ke dalam variabel tersendiri
train_rmse = history.history['root_mean_squared_error']
val_rmse = history.history['val_root_mean_squared_error']

# Menghitung selisih antara nilai training RMSE dan validation RMSE
selisih_rmse = [train_rmse[i] - val_rmse[i] for i in range(len(train_rmse))]

# Buat plot dengan warna dan gaya garis yang berbeda untuk training, validation, dan selisih
plt.plot(train_rmse, color='b', label='Training RMSE')
plt.plot(val_rmse, color='r', linestyle='dashed', label='Validation RMSE')
plt.plot(selisih_rmse, color='g', linestyle='dotted', label='Selisih RMSE')

# Tambahkan judul, label sumbu, dan legenda
plt.title('Root Mean Squared Error History')
plt.xlabel('Epoch')
plt.ylabel('Root Mean Squared Error')
plt.legend(loc='upper right')

# Menambahkan grid untuk memudahkan pembacaan
plt.grid()

# Tampilkan plot
plt.show()

# Menyimpan nilai loss dari training dan validation ke dalam variabel tersendiri
train_rmse = history.history['root_mean_squared_error']
val_rmse = history.history['val_root_mean_squared_error']

# Menentukan epoch yang ingin dicek selisihnya
epoch_to_check = 100

# Mendapatkan nilai training RMSE dan validation RMSE pada epoch tertentu
train_rmse_epoch = train_rmse[epoch_to_check - 1]
val_rmse_epoch = val_rmse[epoch_to_check - 1]

# Menghitung selisih antara nilai training RMSE dan validation RMSE pada epoch tertentu
selisih_rmse_epoch = train_rmse_epoch - val_rmse_epoch

# Menampilkan nilai selisih
print("Nilai selisih pada epoch ke-", epoch_to_check, "adalah:", selisih_rmse_epoch)

# Menyimpan nilai loss dari training dan validation ke dalam variabel tersendiri
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Menyimpan nilai root_mean_squared_error dari training dan validation ke dalam variabel tersendiri
train_rmse = history.history['root_mean_squared_error']
val_rmse = history.history['val_root_mean_squared_error']

# Cetak nilai loss dari training
print("Training Loss:", train_loss)

# Cetak nilai root_mean_squared_error dari training
print("Training RMSE:", train_rmse)

# Cetak nilai loss dari validation
print("Validation Loss:", val_loss)

# Cetak nilai root_mean_squared_error dari validation
print("Validation RMSE:", val_rmse)

"""## **Mendapatkan Rekomendasi Game**"""

game_df = product_new
rating_df = rating_new

user_id = rating_df['user_id'].sample(1).iloc[0]
game_played_by_user = rating_df[rating_df['user_id'] == user_id]

game_not_played = game_df[~game_df['game_id'].isin(game_played_by_user['game_id'].values)]['game_id']
game_not_played = list(
    set(game_not_played)
    .intersection(set(game_to_game_encoded.keys()))
)

game_not_played = [[game_to_game_encoded.get(x)] for x in game_not_played]
user_encoder = user_to_user_encoded.get(user_id)
user_game_array = np.hstack(
    ([[user_encoder]] * len(game_not_played), game_not_played)
)

ratings = model.predict(user_game_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_game_ids = [
    game_encoded_to_game.get(game_not_played[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('========' * 8)
print('Game with high ratings from user')
print('--------' * 8)

top_game_user = (
    game_played_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .game_id.values
)

game_df_rows = game_df[game_df['game_id'].isin(top_game_user)]
for row in game_df_rows.itertuples():
    print(row.title, ':', row.genre)

print('--------' * 8)
print('Top 10 Game Recommendation')
print('--------' * 8)

recommended_game = game_df[game_df['game_id'].isin(recommended_game_ids)]
for row in recommended_game.itertuples():
    print(row.title, ':', row.genre)

second_df.loc[second_df['user_id'] == 470]